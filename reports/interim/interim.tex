%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LaTeX Template: Project Titlepage Modified (v 0.1) by rcx
%
% Original Source: http://www.howtotex.com
% Date: February 2014
% 
% This is a title page template which be used for articles & reports.
% 
% This is the modified version of the original Latex template from
% aforementioned website.
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{report}
\usepackage[a4paper]{geometry}
\usepackage[myheadings]{fullpage}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{graphicx, wrapfig, subcaption, setspace, booktabs}
\usepackage[T1]{fontenc}
\usepackage[font=small, labelfont=bf]{caption}
\usepackage{fourier}
\usepackage[protrusion=true, expansion=true]{microtype}
\usepackage[english]{babel}
\usepackage{sectsty}
\usepackage{url, lipsum}
\usepackage{amsmath}
\usepackage{xfrac}
\setlength{\parindent}{0em}
\setlength{\parskip}{1.2em}

\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}
\onehalfspacing
\setcounter{tocdepth}{5}
\setcounter{secnumdepth}{5}

%-------------------------------------------------------------------------------
% HEADER & FOOTER
%-------------------------------------------------------------------------------
\pagestyle{fancy}
\fancyhf{}
\setlength\headheight{15pt}
\fancyhead[L]{vsv1g12@soton.ac.uk}
\fancyhead[R]{Vlad Velici}
\fancyfoot[R]{Page \thepage\ of \pageref{LastPage}}
%-------------------------------------------------------------------------------
% TITLE PAGE
%-------------------------------------------------------------------------------

\begin{document}

\title{ \normalsize Electronics and Computer Science\\
Faculty of Physical Sciences and Engineering\\
University of Southampton 
        \\ [2.0cm]
        Vlad Sebastian Velici \\
        \today
        \\ [1.0cm]
        {\LARGE \textbf{Similar nodes in large graphs}}
        \\ [1.0cm]
        Project Supervisor: Dr. Adam Prügel-Bennett \\
Second Examiner: Dr. Sasan Mahmoodi
	\\ [2.0cm]
	A progress report submitted for the award of \\
MEng Computer Science with Artificial Intelligence
        \normalsize \vspace*{5\baselineskip}}

\date{}

\maketitle
\tableofcontents
\newpage

%-------------------------------------------------------------------------------
% Section title formatting
\sectionfont{\scshape}
%-------------------------------------------------------------------------------

%-------------------------------------------------------------------------------
% INTRODUCTION
%-------------------------------------------------------------------------------
\section*{Introduction}
\addcontentsline{toc}{section}{Introduction}
%
Plenty of datasets are or can be represented as graphs where vertices represent entities and edges represent relationships between entities. A problem of interest is to find entities that are similarly connected. Example instances of this problem are finding \textit{people you may know} in a social network, people with common interests from research publications repositories or identifying possible duplicates in a dataset.
\par
It is easy to find exact similarities between vertices in small graphs by performing pairwise comparisons. Such an algorithm is too slow for large datasets of millions of vertices. This project investigates a method to compute an approximation of similarities between nodes and attempt to evaluate its performance on different datasets.
%
%-------------------------------------------------------------------------------
% BRUTE FORCE
%-------------------------------------------------------------------------------
%
\section*{Brute-Force Approach}
%
The similarity algorithm is described in regards to the undirected graph $G(v, \epsilon)$ with adjacency matrix $M$. The number of nodes is $N = |v|$ and the number of edges is $|\epsilon|$.
%
In order to derive an algorithm to find similarities between vertices in a graph, a measure of similarity between two vertices must be defined. $M$ is the adjacency matrix of the graph and $M_{i j} = [(i,j) \in \epsilon]$, that is $M_{i j} = 1$ if there is an edge between vertices $i$ and $j$, otherwise $M_{i j} = 0$. Let $D$ be a normalised adjacency matrix such that each column sums up to 1:
%
\begin{equation}
\label{eq:initial-d}
D_{i j} = \frac{1}{\sum_{j=1}^N M_{ij}}
\end{equation}
%
Let $\mathbf{\delta_i}$ be the $i^{th}$ column of the $N \times N$ identity matrix. Let $\mathbf{C_i}$ be a vector that represents how vertex $i$ is connected to the graph. In a brute-force approach, it can be computed as:
%
\begin{equation}
\label{eq:brute-ci}
\mathbf{C_i} = \sum_{t=0}^\infty \mu^t D^t \mathbf{\delta_i}
\end{equation}
%
Where $\mu \in (0,1)$ is a penalising factor. $\mu$ controls how much the far connections are considered into the similarities. Therefore a large $\mu$ enforces consideration of very far connections whereas a small $\mu$ considers far connections less.
%
The similarity between two vertices $i$ and $j$ is the norm of the difference between $\mathbf{C_i}$ and $\mathbf{C_j}$:
%
\begin{equation}
s(i,j) = \|\mathbf{C_i} - \mathbf{C_j}\|
\end{equation}
%
The brute-force approach was run on small randomly generated connected graphs (200 vertices) with 50 iterations and it gave meaningful results but it does not scale for large datasets. In the next section an algorithm that scales to large datasets is described.
%
%-------------------------------------------------------------------------------
% Approximative approach
%-------------------------------------------------------------------------------
%
\section*{Approximative Method}
%
%% Geometry 
%
Geometrically, if vectors $\mathbf{C_i}$ and $\mathbf{C_j}$ start from the origin, then $\mathbf{C_i}$, $\mathbf{C_j}$ and $\mathbf{a} = \mathbf{C_i}-\mathbf{C_j}$ describe a triangle. Let $\theta$ be the angle between $\mathbf{C_i}$ and $\mathbf{C_j}$. From the Law of Cosines:
\begin{equation}
\label{eq:cosinelaw}
\|\mathbf{a}\|^2 = \|\mathbf{C_i}\|^2 + \|\mathbf{C_j}\|^2 - 2  \|\mathbf{C_i}\| \|\mathbf{C_j}\| \cos \ \theta
\end{equation}
%
Take the dot product $\mathbf{C_i^T}\mathbf{C_j} = \| \mathbf{C_i} \| \| \mathbf{C_j} \| \cos \theta$. Observe that the angle between $\mathbf{C_i}$ and itself is 0 and $\cos0=1$, and obtain $\|\mathbf{C_i}\|^2 = \mathbf{C_i^T}\mathbf{C_i}$. Now \emph{Equation~\ref{eq:cosinelaw}} becomes:
\begin{equation}
\label{eq:norm-equation}
\|\mathbf{a}\|^2 = \mathbf{C_i^T}\mathbf{C_i} + \mathbf{C_j^T}\mathbf{C_j} - 2 \mathbf{C_i^T}\mathbf{C_j}
\end{equation}
%
Therefore it is sufficient to be able to compute all dot products $\mathbf{C_i^T}\mathbf{C_j}$ (for all $i, j \in v$) to compute the similarities between all vertices of the graph. Computing and storing all $\mathbf{C_i^T}\mathbf{C_j}; i,j \in v$ takes too much time and memory for a very large dataset if we use the brute-force approach.
%
\par
%
%% Approximative algorithm intro
%
An approximative algorithm to efficiently compute the dot products $\mathbf{C_i^T}\mathbf{C_j}$ will be described. Let $W$ be a diagonal matrix:
%
\begin{equation}
\label{eq:W}
W_{ij} = \frac{[i=j]}{\sum_{j=1}^N M_{ij}}
\end{equation}
%
Now \emph{Equation~\ref{eq:initial-d}} can be written as $D = WM$, thus 
%
\begin{equation}
\label{eq:newdt}
D^t = (WM)^t
\end{equation}
%
%
Define a new matrix $A$:
%
\begin{equation}
\label{eq:a}
A = W^{\sfrac{1}{2}}MW^{\sfrac{1}{2}}
\end{equation}
%
%
From \emph{Equation~\ref{eq:newdt}} and \emph{Equation~\ref{eq:a}}:
%
\begin{equation}
\label{eq:used-dt}
D^t = W^{\sfrac{1}{2}} A^t W^{\sfrac{-1}{2}}
\end{equation}
%
%
The matrices $W^{\sfrac{1}{2}}$ and $W^{\sfrac{-1}{2}}$ are easy to compute because $W$ is a diagonal matrix. Apply the matrix operation only on the diagonal elements and obtain $(W^{\sfrac{1}{2}})_{ii} = (W_{ii})^{\sfrac{1}{2}}$ and $(W^{\sfrac{-1}{2}})_{ii} = (W_{ii})^{\sfrac{-1}{2}}$.
%
\par
%
%% Defining eigen*matrixes.
%
Let $\lambda_i$ be the $i^{th}$ eigenvalue and $\bigvee^{(i)}$ be the $i^{th}$ eigenvector ($\forall i \in \{ 1, 2, ..., N \}$). $\bigvee$ is a matrix of all computed eigenvectors (such that $\bigvee^{(i)}$ is the $i^{th}$ column of $\bigvee$), and $\bigwedge$ is a diagonal matrix of all computed eigenvalues:
\begin{align}
\bigvee      &=  \begin{bmatrix}
\vert & \vert &  & \vert \\
\bigvee^{(1)} & \bigvee^{(2)} & \dots & \bigvee^{(N)}\\
\vert & \vert &  & \vert \end{bmatrix} \\
\bigwedge &= \begin{bmatrix}
\lambda_1 & 0 		      & \dots  & 0\\
0 	 	 & \lambda_2  & \dots  &  0\\
\vdots 	 & \vdots	      & \ddots & \\
0	          & 0                  &            & \lambda_N
\end{bmatrix}
\end{align}
%
%% Eigenvalue decomposition
%
The eigendecomposition of the matrix A is $A = \bigvee \bigwedge \bigvee\nolimits^{-1}$. The graph $G$ is an undirected graph which makes $A$ a real symmetric matrix, thus $\bigvee\nolimits^{-1} = \bigvee\nolimits^{T}$. The eigendecomposition of the matrix $A$ is therefore:
\begin{align}
A &= \bigvee \bigwedge \bigvee\nolimits^{T} \\
\Rightarrow A^t &= \big(\bigvee \bigwedge \bigvee\nolimits^{T}\big)^t = \bigvee \bigwedge\nolimits^t \bigvee\nolimits^{T} \\
\Leftrightarrow A^t &= \sum_{a=1}^{N} \lambda_a^t \bigvee\nolimits^{(a)} \bigvee\nolimits^{(a)^T} \label{eq:a-at-t-sum} 
\end{align} 
%
From \emph{Equation~\ref{eq:used-dt}} and \emph{Equation~\ref{eq:a-at-t-sum}}:
\begin{equation}
\label{eq:d-at-t-with-a}
D^t = W^{\sfrac{1}{2}} \sum_{a=1}^{N} \lambda_a^t \bigvee\nolimits^{(a)} \bigvee\nolimits^{(a)^T} W^{\sfrac{-1}{2}}
\end{equation}
%
%% Plugging into the Ci
%
Plug $D^t$ from \emph{Equation~\ref{eq:d-at-t-with-a}} into \emph{Equation~\ref{eq:brute-ci}}:
\begin{equation}
\mathbf{C_i} = \sum_{t=0}^\infty \mu^t W^{\sfrac{1}{2}} \sum_{a=1}^{N} \lambda_a^t \bigvee\nolimits^{(a)} \bigvee\nolimits^{(a)^T} W^{\sfrac{-1}{2}} \mathbf{\delta_i}
\end{equation}
Rearrange the equation and obtain:
\begin{equation}
\label{eq:ci-rearranged}
\mathbf{C_i} = W^{\sfrac{1}{2}} \sum_{a=1}^{N} \sum_{t=0}^\infty \mu^t  \lambda_a^t \bigvee\nolimits^{(a)} \bigvee\nolimits^{(a)^T} W^{\sfrac{-1}{2}} \mathbf{\delta_i}
\end{equation}
%
%% Geometric series - to look into lambda mu < 1.
%
Note that $\sum_{t=0}^\infty \mu^t\lambda_a^t$ is a sum of a geometric series with the first term $1$ and ratio $\mu \lambda_a$, therefore:
\begin{equation}
\label{eq:geometric-series}
\sum_{t=0}^\infty \mu^t\lambda_a^t = \frac{1}{1 - \mu \lambda_a}
\end{equation}
%
Observe $\bigvee\nolimits^{(a)^T} W^{\sfrac{-1}{2}} \mathbf{\delta_i}$ is a scalar:
\begin{equation}
\label{eq:observe-scalar}
\bigvee\nolimits^{(a)^T} W^{\sfrac{-1}{2}} \mathbf{\delta_i} = \bigvee\nolimits^{(a)}_i W^{\sfrac{-1}{2}}_{ii}
\end{equation}
%
Substitute \emph{Equation~\ref{eq:observe-scalar}} and \emph{Equation~\ref{eq:geometric-series}} back into \emph{Equation~\ref{eq:ci-rearranged}} and obtain:
\begin{equation}
\label{eq:ci-rearranged-geometric}
\mathbf{C_i} = W^{\sfrac{1}{2}} \sum_{a=1}^{N} \frac{1}{1 - \mu \lambda_a} \bigvee\nolimits^{(a)} \bigvee\nolimits^{(a)}_i W^{\sfrac{-1}{2}}_{ii}
\end{equation}
%
%% Define Z
%
To simplify the equation, let $Z$ be a matrix such that:
\begin{equation}
\label{eq:z-ij}
Z_{ij} = \frac{\bigvee\nolimits^{(j)}_i W^{\sfrac{-1}{2}}_{ii}}{1-\mu \lambda_j}
\end{equation}
%
Substitute in \emph{Equation~\ref{eq:ci-rearranged-geometric}} and get:
%
\begin{equation}
\label{eq:ci-rearranged-z}
\mathbf{C_i} = W^{\sfrac{1}{2}} \sum_{a=1}^{N} Z_{ia} \bigvee\nolimits^{(a)}
\end{equation}
%
The dot product between $\mathbf{C_i}$ and $\mathbf{C_j}$ becomes:
\begin{align}
%
\mathbf{C_i^T} \mathbf{C_j} &= \Big(  W^{\sfrac{1}{2}} \sum_{a=1}^{N} Z_{ia} \bigvee\nolimits^{(a)} \Big)^T \Big(  W^{\sfrac{1}{2}} \sum_{a'=1}^{N} Z_{ia'} \bigvee\nolimits^{(a')} \Big)
\\
\Leftrightarrow \mathbf{C_i^T} \mathbf{C_j} &= \sum_{a=1}^{N} Z_{ia}  \bigvee\nolimits^{(a)^T} W \sum_{a'=1}^{N} Z_{ia'} \bigvee\nolimits^{(a')}
\\
\Leftrightarrow \mathbf{C_i^T} \mathbf{C_j} &= \sum_{a=1}^N \sum_{a'=1}^N Z_{ia} Z_{ja'} \bigvee\nolimits^{(a)^T} W \bigvee\nolimits^{(a')} \label{eq:dot-zvw}
\end{align}
%
%% Define Q
%
Define a new matrix $Q$ such that:
\begin{equation}
\label{eq:q-ij}
Q_{ij} = \bigvee\nolimits^{(i)^T} W \bigvee\nolimits^{(j)}
\end{equation}
Substitute $Q$ into \emph{Equation~\ref{eq:dot-zvw}} and obtain:
\begin{align}
\mathbf{C_i^T} \mathbf{C_j} &= \sum_{a=1}^N \sum_{a'=1}^N Z_{ia} Z_{ja'} Q_{aa'} \label{eq:dot-zq-sum} \\
\Leftrightarrow \mathbf{C_i^T} \mathbf{C_j} &= \mathbf{Z_i^T} Q \mathbf{Z_j} \label{eq:dot-zq-vectorised}
\end{align}
%
%% Approximation explained.
%
An approximation of the vectors $\mathbf{C_i} (\forall i \in v)$ can be obtained by only using the $m$ leading eigenvectors and eigenvalues of $A$ instead of all of them. Compute the largest $m$ eigenvalues and eigenvectors of the matrix $A$ using the Lanczos Method for real symmetric matrices[1]. For directed graphs the Arnoldi Iteration[2] will be used instead. These algorithms perform well on large sparse matrices. In real datasets it is very often the case that the number of edges is orders of magnitude smaller than the number of vertices squared, resulting in sparse adjacency matrices and a sparse $A$. Define $\mathbf{\hat{C_i}}$ to be an approximation of $\mathbf{C_i}$:
\begin{equation}
\label{eq:c-hat}
\mathbf{\hat{C_i}} = W^{\sfrac{1}{2}} \sum_{a=1}^{m} Z_{ia} \bigvee\nolimits^{(a)}
\end{equation}
In implementation, the matrix $Z$ is only used to compute $\mathbf{\hat{C_i^T}}\mathbf{\hat{C_j}}$, therefore in the implementation it will be of size $N \times m$.


\par
%
%-------------------------------------------------------------------------------
% LIMITATIONS
%-------------------------------------------------------------------------------
\section*{Limitations of Current Implementation}
The current implementation of this algorithm has various limitations which are discussed along with possible improvements.
%
\paragraph*{Only undirected graphs} Directed graphs are not currently supported. In practice, datasets have meaningful unidirectional relationships (e.g. in a social network person A follows person B, but B does not follow A), and often datasets are represented as directed graphs rather than undirected graphs. The algorithm can be adapted to support both directed and undirected graphs but it will have the disadvantage of requiring to compute $V^{-1}$ (for undirected graphs, $V^{-1} = V^T$).
%
\paragraph*{Ignored relationship types} In the real world datasets might have different types of relationships between entities. Some relationship types might be more relevant than others in finding a specific result. For instance, in a social network two people being friends might be more relevant for recommending new friends than two people following the same topic. The current implementation of the algorithm can compute similarities if it is given a weighted (symmetric) adjacency matrix but it does not have a way to automatically obtain these weights from the dataset.

\paragraph*{Not distributed} What if the dataset is too large to fit into main memory? The algorithm is currently only designed to run on one machine. Methods of distributing the algorithm on more than one machine over a network will be investigated in the future.

%-------------------------------------------------------------------------------
% REFERENCES
%-------------------------------------------------------------------------------
\newpage
\section*{References}
\addcontentsline{toc}{section}{References}

[1]: Calvetti, Daniela, L. Reichel, and Danny Chris Sorensen. "An implicitly restarted Lanczos method for large symmetric eigenvalue problems." Electronic Transactions on Numerical Analysis 2.1 (1994): 21.

[2]: Lehoucq, Richard B., and Danny C. Sorensen. "Deflation techniques for an implicitly restarted Arnoldi iteration." SIAM Journal on Matrix Analysis and Applications 17.4 (1996): 789-821.

\end{document}

%-------------------------------------------------------------------------------
% SNIPPETS
%-------------------------------------------------------------------------------

%\begin{figure}[!ht]
%   \centering
%   \includegraphics[width=0.8\textwidth]{file_name}
%   \caption{}
%   \centering
%   \label{label:file_name}
%\end{figure}

%\begin{figure}[!ht]
%   \centering
%   \includegraphics[width=0.8\textwidth]{graph}
%   \caption{Blood pressure ranges and associated level of hypertension (American Heart Association, 2013).}
%   \centering
%   \label{label:graph}
%\end{figure}

%\begin{wrapfigure}{r}{0.30\textwidth}
%   \vspace{-40pt}
%   \begin{center}
%       \includegraphics[width=0.29\textwidth]{file_name}
%   \end{center}
%   \vspace{-20pt}
%   \caption{}
%   \label{label:file_name}
%\end{wrapfigure}

%\begin{wrapfigure}{r}{0.45\textwidth}
%   \begin{center}
%       \includegraphics[width=0.29\textwidth]{manometer}
%   \end{center}
%   \caption{Aneroid sphygmomanometer with stethoscope (Medicalexpo, 2012).}
%   \label{label:manometer}
%\end{wrapfigure}

%\begin{table}[!ht]\footnotesize
%   \centering
%   \begin{tabular}{cccccc}
%   \toprule
%   \multicolumn{2}{c} {Pearson's correlation test} & \multicolumn{4}{c} {Independent t-test} \\
%   \midrule    
%   \multicolumn{2}{c} {Gender} & \multicolumn{2}{c} {Activity level} & \multicolumn{2}{c} {Gender} \\
%   \midrule
%   Males & Females & 1st level & 6th level & Males & Females \\
%   \midrule
%   \multicolumn{2}{c} {BMI vs. SP} & \multicolumn{2}{c} {Systolic pressure} & \multicolumn{2}{c} {Systolic Pressure} \\
%   \multicolumn{2}{c} {BMI vs. DP} & \multicolumn{2}{c} {Diastolic pressure} & \multicolumn{2}{c} {Diastolic pressure} \\
%   \multicolumn{2}{c} {BMI vs. MAP} & \multicolumn{2}{c} {MAP} & \multicolumn{2}{c} {MAP} \\
%   \multicolumn{2}{c} {W:H ratio vs. SP} & \multicolumn{2}{c} {BMI} & \multicolumn{2}{c} {BMI} \\
%   \multicolumn{2}{c} {W:H ratio vs. DP} & \multicolumn{2}{c} {W:H ratio} & \multicolumn{2}{c} {W:H ratio} \\
%   \multicolumn{2}{c} {W:H ratio vs. MAP} & \multicolumn{2}{c} {\% Body fat} & \multicolumn{2}{c} {\% Body fat} \\
%   \multicolumn{2}{c} {} & \multicolumn{2}{c} {Height} & \multicolumn{2}{c} {Height} \\
%   \multicolumn{2}{c} {} & \multicolumn{2}{c} {Weight} & \multicolumn{2}{c} {Weight} \\
%   \multicolumn{2}{c} {} & \multicolumn{2}{c} {Heart rate} & \multicolumn{2}{c} {Heart rate} \\
%   \bottomrule
%   \end{tabular}
%   \caption{Parameters that were analysed and related statistical test performed for current study. BMI - body mass index; SP - systolic pressure; DP - diastolic pressure; MAP - mean arterial pressure; W:H ratio - waist to hip ratio.}
%   \label{label:tests}
%\end{table}